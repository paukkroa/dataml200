{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f7199d-c442-4732-ab89-83bda42682a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "90f7199d-c442-4732-ab89-83bda42682a7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de21aae042b148f4ce345abc2630f326",
     "grade": false,
     "grade_id": "cell-b2bf973e50b54a30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Exercise 5: Machine Translation with Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f8445f",
   "metadata": {
    "editable": true,
    "id": "b6f8445f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False   # You can set it to True if you want to run inference on your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
   "metadata": {
    "editable": true,
    "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/content/dataset_ex5\" # you can change the path if you want to store the dataset somewhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb6f08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cbdb6f08",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8527fd780788625a34b40348b30de440",
     "grade": false,
     "grade_id": "cell-39478e54ddb16815",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6feccd",
   "metadata": {
    "editable": true,
    "id": "0b6feccd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for all libraries\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9f32a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1a9f32a0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "310824e7fb50a67093ebb7f92521f386",
     "grade": false,
     "grade_id": "cell-3ac688ddcdf1f718",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "851f4281950105edf2038c35a19db963",
     "grade": false,
     "grade_id": "cell-91357d14fc99d39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f4723736e3e4512d6d08504b7a0dbd6",
     "grade": false,
     "grade_id": "cell-291860bd3393c1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.1: Tokenizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": false,
    "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
    "outputId": "5ba23595-4338-4b18-df22-99a7de3b3e4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 137860 English sentences in data\n",
      "There are 137860 French sentences in data\n",
      "Here are some examples:\n",
      "----------\n",
      "new jersey is sometimes quiet during autumn \n",
      "new jersey est parfois calme pendant l' automne \n",
      "----------\n",
      "they like strawberries \n",
      "ils aiment les fraises \n",
      "----------\n",
      "she plans to visit the united states next may .\n",
      "elle envisage de se rendre aux états-unis en mai prochain .\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "en_df = pd.read_csv(os.path.join(path , 'small_vocab_en.csv'), header=None, usecols=[0])\n",
    "fr_df = pd.read_csv(os.path.join(path, 'small_vocab_fr.csv'), header=None, usecols=[0])\n",
    "\n",
    "english_sentences = en_df[0].values\n",
    "french_sentences = fr_df[0].values\n",
    "\n",
    "print(f'There are {len(english_sentences)} English sentences in data')\n",
    "print(f'There are {len(french_sentences)} French sentences in data')\n",
    "print('Here are some examples:')\n",
    "e = [ 0, 1000, 3000]\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(english_sentences[i])\n",
    "    print(french_sentences[i])\n",
    "print(100*\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": true,
    "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e136e2d6e0d0fe41dcc0ed1b4265e4b3",
     "grade": false,
     "grade_id": "cell-d953178b4a066fcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "7df51196-c8eb-4ab5-ecbe-a7b85f0f0402",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "['new', 'jersey', 'is', 'sometimes', 'quiet', 'during', 'autumn']\n",
      "['new', 'jersey', 'est', 'parfois', 'calme', 'pendant', \"l'\", 'automne']\n",
      "----------\n",
      "['they', 'like', 'strawberries']\n",
      "['ils', 'aiment', 'les', 'fraises']\n",
      "----------\n",
      "['she', 'plans', 'to', 'visit', 'the', 'united', 'states', 'next', 'may']\n",
      "['elle', 'envisage', 'de', 'se', 'rendre', 'aux', 'étatsunis', 'en', 'mai', 'prochain']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize function\n",
    "def tokenize(sentences):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of sentences by:\n",
    "    1. Converting all text to lowercase.\n",
    "    2. Removing special characters listed in \"filters\".\n",
    "    Hint: you can use \"str.maketrans\" to creates a translation table to remove unwanted characters defined in \"filters\".\n",
    "    3. Splitting each sentence into a list of words.\n",
    "    \"\"\"\n",
    "    filters = '.?!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "    tokenized_list = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(str.maketrans('', '', filters))\n",
    "        tokenized_list.append(sentence.split())\n",
    "\n",
    "    return tokenized_list\n",
    "\n",
    "# Tokenize English and French sentences\n",
    "tokenized_en = tokenize(english_sentences)\n",
    "tokenized_fr = tokenize(french_sentences)\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(tokenized_en[i])\n",
    "    print(tokenized_fr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc71a52-0148-4bce-af72-799047b0f653",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bfc71a52-0148-4bce-af72-799047b0f653",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0907496be0bbf0e8a9587a38d054ac63",
     "grade": false,
     "grade_id": "cell-5c42169eb0d9ba7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.2: Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": true,
    "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b4b871a691fb80fb59f818abe16af6",
     "grade": false,
     "grade_id": "cell-acd8f7a88e74d5a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "56766c4a-06fe-4394-ae5e-ecfdcf13d21a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples from our English dictionary: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "word: <PAD>, index: 0\n",
      "word: <SOS>, index: 1\n",
      "word: <EOS>, index: 2\n",
      "word: new, index: 3\n",
      "word: jersey, index: 4\n",
      "word: is, index: 5\n",
      "word: sometimes, index: 6\n",
      "word: quiet, index: 7\n",
      "word: during, index: 8\n",
      "word: autumn, index: 9\n",
      "__________\n",
      "index: 0, word: <PAD>\n",
      "index: 1, word: <SOS>\n",
      "index: 2, word: <EOS>\n",
      "index: 3, word: new\n",
      "index: 4, word: jersey\n",
      "index: 5, word: is\n",
      "index: 6, word: sometimes\n",
      "index: 7, word: quiet\n",
      "index: 8, word: during\n",
      "index: 9, word: autumn\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary with special tokens\n",
    "def build_vocab(tokenized_sentences):\n",
    "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "    # build vocab by applying \"Counter\" for sentence in tokenized_sentences and for token in sentence\n",
    "    # add special tokens\n",
    "    # word2idx = ? (a dictionary for mapping word to index)\n",
    "    # idx2word = ? (a dictionary for index to word)\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "\n",
    "    # add special tokens to the vocab\n",
    "    for i, token in enumerate(special_tokens):\n",
    "        word2idx[token] = i\n",
    "        idx2word[i] = token\n",
    "\n",
    "    # add the rest of the words to the vocab\n",
    "    idx = len(special_tokens)\n",
    "    for sentence in tokenized_sentences:\n",
    "        for token in sentence:\n",
    "            # check if token exists already\n",
    "            if token not in word2idx:\n",
    "                word2idx[token] = idx\n",
    "                idx2word[idx] = token\n",
    "                idx += 1\n",
    "\n",
    "    return word2idx, idx2word\n",
    "\n",
    "en_word2idx, en_idx2word = build_vocab(tokenized_en)\n",
    "fr_word2idx, fr_idx2word = build_vocab(tokenized_fr)\n",
    "\n",
    "print(\"Here are some examples from our English dictionary: \")\n",
    "print(100 * \"-\")\n",
    "\n",
    "# Display first 10 words and their indices from en_word2idx\n",
    "for i, (key, value) in enumerate(en_word2idx.items()):\n",
    "    print(f'word: {key}, index: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break\n",
    "\n",
    "print(10 * \"_\")\n",
    "\n",
    "# Display first 10 indices and their words from en_idx2word\n",
    "for i, (key, value) in enumerate(en_idx2word.items()):\n",
    "    print(f'index: {key}, word: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604ca38-063e-46cb-a40e-57192653a316",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4604ca38-063e-46cb-a40e-57192653a316",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc164a3386abefc31af298f532ab98d0",
     "grade": false,
     "grade_id": "cell-2b2c9232a9907c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
    "outputId": "0f10f8b3-e9bd-441b-ef65-0da60a1d5546",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch: tensor([[  1,  39,  65,   5,   6, 104,  15,  64,   2,   0]], device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "__________\n",
      "Target batch: tensor([[ 1, 58,  5,  6, 87,  8, 57,  2,  0,  0]], device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "# Dataset class with padding applied in __getitem__\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, seq_len=30):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.tgt_sentences = tgt_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def pad_sequence(self, tokens, vocab, is_target=False):\n",
    "        \"\"\"\n",
    "        Pads a sequence of tokens to the fixed length `seq_len`.\n",
    "        Adds <SOS> at the start, <EOS> at the end, and pads with <PAD>.\n",
    "        Trims if the sequence is longer than `seq_len`.\n",
    "        \"\"\"\n",
    "        tokens = [vocab[\"<SOS>\"]] + [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]\n",
    "        tokens.append(vocab[\"<EOS>\"])\n",
    "        tokens = tokens[:self.seq_len]\n",
    "        tokens += [vocab[\"<PAD>\"]] * (self.seq_len - len(tokens))\n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        src_tokens = self.src_sentences[idx]\n",
    "        tgt_tokens = self.tgt_sentences[idx]\n",
    "\n",
    "        # Apply padding to both the source and target sentences\n",
    "        src_padded = self.pad_sequence(src_tokens, self.src_vocab, is_target=False)\n",
    "        tgt_padded = self.pad_sequence(tgt_tokens, self.tgt_vocab, is_target=True)\n",
    "\n",
    "        # Convert to tensors and move to device (GPU or CPU)\n",
    "        src_item = torch.tensor(src_padded).to(device)\n",
    "        tgt_item = torch.tensor(tgt_padded).to(device)\n",
    "\n",
    "        return src_item, tgt_item\n",
    "\n",
    "# Instantiate and test the dataset, let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test the DataLoader\n",
    "for src_batch, tgt_batch in dataloader:\n",
    "    print(\"Source batch:\", src_batch)\n",
    "    print(src_batch.size())\n",
    "    print(10*\"_\")\n",
    "    print(\"Target batch:\", tgt_batch)\n",
    "    print(tgt_batch.size())\n",
    "    print(10*\"_\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a920ba916dac6fa8032a24c0603867eb",
     "grade": false,
     "grade_id": "cell-5ddb30e4fc5234fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.3: Sentence Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": true,
    "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e641ffdf106f543f00d6a776e3963eb",
     "grade": false,
     "grade_id": "cell-fab72a3e23c8b68e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "07180942-b90c-47d5-bfcd-f3c76f9caeb5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n",
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "vsize_src = len(fr_word2idx)\n",
    "vsize_tgt = len(en_word2idx)\n",
    "\n",
    "# data: let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Use 'next' to get a batch from the DataLoader iterator\n",
    "src_batch, tgt_batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "embedding_fr = nn.Embedding(vsize_src, embedding_size) #(define an embedding layer for French words in your French Vocabulary)\n",
    "embedding_fr.to(device)\n",
    "output_embedding_fr = embedding_fr(src_batch) #(pass src_batch through embedding_fr)\n",
    "\n",
    "\n",
    "embedding_en = nn.Embedding(vsize_tgt, embedding_size) # (define an embedding layer for English words in your English Vocabulary)\n",
    "embedding_en.to(device)\n",
    "output_embedding_en = embedding_en(tgt_batch)\n",
    "\n",
    "print(10*\"_\")\n",
    "print(src_batch.size())\n",
    "print(output_embedding_fr.size())\n",
    "print(10*\"_\")\n",
    "print(tgt_batch.size())\n",
    "print(output_embedding_en.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "478bcf1a7168a93463c0482b18b80bbf",
     "grade": false,
     "grade_id": "cell-8372a80b53e83a10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.4: Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66ff2d4d083b95d6edb7f6e17233b63e",
     "grade": false,
     "grade_id": "cell-de1d08bfdff6d81e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # Initialize a tensor to store positional encodings for each position up to max_len\n",
    "        pos_encoding = torch.zeros(max_len, embed_size)\n",
    "        # Create a tensor for positions, where each position corresponds to a word's position in the sequence\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # 1. Create a tensor `div_term` to scale the positional encoding values.\n",
    "\n",
    "        # Hint:\n",
    "        # This is based on the formula for positional encoding where each dimension has a different frequency.\n",
    "        # We generate a range of values from 0 to embed_size, stepping by 2 (for even indices), and multiply it by a scaling factor.\n",
    "        # The scaling factor (-math.log(10000.0) / embed_size) ensures the frequencies decay logarithmically.\n",
    "\n",
    "        # 2. Apply the sine function to the even indices of the positional encoding matrix.\n",
    "        # 3. Apply the cosine function to the odd indices of the positional encoding matrix.\n",
    "\n",
    "        # Hint:\n",
    "        # The `position` tensor holds the position values for each token, and `div_term` scales those values.\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size))\n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Register as buffer so it is not considered as a parameter during training\n",
    "        self.register_buffer('pos_encoding', pos_encoding.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to embeddings\n",
    "        x = x * math.sqrt(self.embed_size)\n",
    "        x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": false,
    "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
    "outputId": "3e46fd8a-2a65-4d5e-9ed6-7072b95eb1e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "torch.Size([1, 10, 128])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "#%% Applying positional encoding\n",
    "positional_encoding = PositionalEncoding(embedding_size, 512)\n",
    "output_pe_fr = positional_encoding (output_embedding_fr)\n",
    "output_pe_en = positional_encoding (output_embedding_en)\n",
    "print(10*\"_\")\n",
    "print(output_pe_fr.size())\n",
    "print(output_pe_en.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29456a0467e8a115f33b88974dd4d293",
     "grade": false,
     "grade_id": "cell-093e16e5c4566696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b428830c77336df8f215865a3b76a1",
     "grade": false,
     "grade_id": "cell-8acf47d49c2ce752",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
    "        super(MyTransformer, self).__init__()\n",
    "        # Initialize layers similar to MySimpleTransformer\n",
    "        # Two Embedding layers for source and target text\n",
    "        # Positional encoding\n",
    "        # Transformer block\n",
    "        # Final linear layer to project transformer output to vocab size\n",
    "        self.embedding_src = nn.Embedding(vocab_size_src, embed_size).to(device)\n",
    "        self.embedding_tgt = nn.Embedding(vocab_size_tgt, embed_size).to(device)\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "        self.transformer = nn.Transformer(d_model=embed_size,\n",
    "                                          nhead=num_heads,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=hidden_dim)\n",
    "        self.linear = nn.Linear(embed_size, vocab_size_tgt)\n",
    "\n",
    "    def encode(self, src, src_padding_mask):\n",
    "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
    "        src = src.transpose(0, 1)\n",
    "\n",
    "        # 1. Get embeddings for source\n",
    "        # 2. apply positional encoding to embedded source\n",
    "        # 3. Forward pass to Transformer encoder block with src_key_padding_mask\n",
    "        src_embedding = self.embedding_src(src)\n",
    "        src_pe = self.positional_encoding(src_embedding)\n",
    "        encoded = self.transformer.encoder(src_pe,\n",
    "                               src_key_padding_mask=src_padding_mask)\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, tgt_padding_mask):\n",
    "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "        if tgt_mask != None:\n",
    "            tgt_mask = tgt_mask.transpose(0,1)\n",
    "\n",
    "        # 1. Get embeddings for target\n",
    "        # 2. apply positional encoding to embedded target\n",
    "        # 3. Forward pass target and memory (output of encode) to Transformer decoder block with tgt_mask\n",
    "        tgt_embedding = self.embedding_tgt(tgt)\n",
    "        tgt_pe = self.positional_encoding(tgt_embedding)\n",
    "        decoded = self.transformer.decoder(tgt_pe,\n",
    "                               memory,\n",
    "                               tgt_mask=tgt_mask,\n",
    "                               tgt_key_padding_mask=tgt_padding_mask)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
    "        # 1. pass source through encode block (name it as memory)\n",
    "        # 2. pass target and memory through decode block\n",
    "        # 3. Project to vocabulary size\n",
    "        memory = self.encode(src,\n",
    "                             src_padding_mask)\n",
    "        output_decoder = self.decode(tgt,\n",
    "                                     memory,\n",
    "                                     tgt_mask,\n",
    "                                     tgt_padding_mask)\n",
    "        output = self.linear(output_decoder)\n",
    "\n",
    "        output = output.transpose(0, 1)\n",
    "        return  output_decoder, output\n",
    "\n",
    "    def get_tgt_mask(self, tgt):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "        return tgt_mask\n",
    "\n",
    "    def create_pad_mask(self, matrix):\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        pad_token = 0\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfdc594c1314d46e6f092e7117d03e55",
     "grade": false,
     "grade_id": "cell-2f77cd749e40453a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 3: Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b833b15-348a-447c-9c6e-185ec36736d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5b833b15-348a-447c-9c6e-185ec36736d7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e3d07d2cc6c623d73b169e5acc2771b",
     "grade": false,
     "grade_id": "cell-50417a72b48171e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "bs = 256\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=7)\n",
    "number_of_sentences = len(tokenized_fr)\n",
    "train_size = int((0.8)*number_of_sentences)\n",
    "test_size = int(number_of_sentences - train_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ada45fd309f153dcb7c3f001c5acddc8",
     "grade": false,
     "grade_id": "cell-47986e3c9b4441ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "embedding_size = 240 # embed_dim must be divisible by num_heads\n",
    "vsize_src = len(fr_word2idx) # 336\n",
    "vsize_tgt = len(en_word2idx) # 201\n",
    "hdim = 512\n",
    "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 6, hdim, 4, 4, max_len=256)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "deletable": false,
    "editable": true,
    "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65de115ec5ce2d0baed8313bf2220f2b",
     "grade": false,
     "grade_id": "cell-3e78e5aa606c25be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "bc0fb3db-bca8-4d6d-fea4-43419fff6dc3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.0225\n",
      "Epoch 1/10, Validation Loss: 0.1464\n",
      "Epoch 2/10, Train Loss: 0.133\n",
      "Epoch 2/10, Validation Loss: 0.0899\n",
      "Epoch 3/10, Train Loss: 0.0927\n",
      "Epoch 3/10, Validation Loss: 0.0783\n",
      "Epoch 4/10, Train Loss: 0.0817\n",
      "Epoch 4/10, Validation Loss: 0.0743\n",
      "Epoch 5/10, Train Loss: 0.0769\n",
      "Epoch 5/10, Validation Loss: 0.0729\n",
      "Epoch 6/10, Train Loss: 0.0744\n",
      "Epoch 6/10, Validation Loss: 0.0731\n",
      "Epoch 7/10, Train Loss: 0.0731\n",
      "Epoch 7/10, Validation Loss: 0.0712\n",
      "Epoch 8/10, Train Loss: 0.0717\n",
      "Epoch 8/10, Validation Loss: 0.0699\n",
      "Epoch 9/10, Train Loss: 0.0711\n",
      "Epoch 9/10, Validation Loss: 0.0696\n",
      "Epoch 10/10, Train Loss: 0.0702\n",
      "Epoch 10/10, Validation Loss: 0.0703\n",
      "Training completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABh7klEQVR4nO3dd3xT9f7H8XeaDlrasumASkHZQhkVL6ACyhAUFRyAKOM6rhe4iOjvCkpLoSpOLteBKFfFAYoiOFEoCIqAAmIRBXGwN4hQoHSQ5PfHMaGhhe6cjNfz8TiPJCcnySfJF82733M+x+JwOBwCAAAAAJxTkNkFAAAAAIC3IzgBAAAAQDEITgAAAABQDIITAAAAABSD4AQAAAAAxSA4AQAAAEAxCE4AAAAAUAyCEwAAAAAUg+AEAAAAAMUgOAGAnxs2bJgSExPNLsM027dvl8Vi0axZs1zr0tLSZLFYSvR4i8WitLS0Cq2pa9eu6tq1a4U+JwCgchGcAMAkFoulRMvy5cvNLtVjrrvuOkVEROj48ePn3Gbw4MEKDQ3VH3/84cHKSm/Tpk1KS0vT9u3bzS7FZfny5bJYLJo3b57ZpQCAzwk2uwAACFRvvvmm2+033nhDGRkZhdY3b968XK8zc+ZM2e32cj2HpwwePFgff/yxFixYoCFDhhS6Pzs7Wx9++KGuvvpq1apVq8yvM2HCBI0bN648pRZr06ZNmjRpkrp27Vpoxm/x4sWV+toAgIpHcAIAk9x2221ut7/55htlZGQUWn+27OxsRURElPh1QkJCylSfGa677jpFRUVpzpw5RQanDz/8UCdPntTgwYPL9TrBwcEKDjbvf4GhoaGmvTYAoGzYVQ8AvFjXrl118cUX67vvvtMVV1yhiIgIPfTQQ5KMEHHNNdcoPj5eYWFhuvDCC5Weni6bzeb2HGcf4+Q85ufpp5/Wyy+/rAsvvFBhYWG65JJLtHbt2vPWs27dOlksFr3++uuF7lu0aJEsFos++eQTSdLx48c1ZswYJSYmKiwsTHXr1lWPHj20fv36cz5/eHi4+vfvr6VLl+rgwYOF7p8zZ46ioqJ03XXX6ciRI3rggQfUqlUrRUZGKjo6Wr1799aGDRvO+x6koo9xys3N1X333ac6deq4XmP37t2FHrtjxw6NGDFCTZs2VXh4uGrVqqWbb77ZbZe8WbNm6eabb5YkdevWrdBul0Ud43Tw4EHdcccdiomJUZUqVZSUlFTocy7Pd1caW7du1c0336yaNWsqIiJCf/vb3/Tpp58W2u65555Ty5YtFRERoRo1aig5OVlz5sxx3V+WMQAA3ooZJwDwcn/88Yd69+6tgQMH6rbbblNMTIwk48d5ZGSkxo4dq8jISH3xxRdKTU1VVlaWnnrqqWKfd86cOTp+/Lj+8Y9/yGKx6Mknn1T//v21devWc85SJScnq1GjRnr33Xc1dOhQt/vmzp2rGjVqqFevXpKke+65R/PmzdOoUaPUokUL/fHHH/r666+1efNmtWvX7px1DR48WK+//rreffddjRo1yrX+yJEjWrRokQYNGqTw8HD99NNP+uCDD3TzzTerYcOGOnDggF566SV16dJFmzZtUnx8fLGfQUF33nmn3nrrLd16663q1KmTvvjiC11zzTWFtlu7dq1WrVqlgQMHqn79+tq+fbtefPFFde3aVZs2bVJERISuuOIKjR49Ws8++6weeugh1+6W59rt8tSpU+ratat+++03jRo1Sg0bNtR7772nYcOG6ejRo7r33nvdti/Ld1dSBw4cUKdOnZSdna3Ro0erVq1aev3113Xddddp3rx56tevnyRjF9DRo0frpptu0r333qucnBz98MMP+vbbb3XrrbdKKvsYAACv5AAAeIWRI0c6zv7PcpcuXRySHDNmzCi0fXZ2dqF1//jHPxwRERGOnJwc17qhQ4c6GjRo4Lq9bds2hyRHrVq1HEeOHHGt//DDDx2SHB9//PF56xw/frwjJCTE7bG5ubmO6tWrO/7+97+71lWrVs0xcuTI8z5XUU6fPu2Ii4tzdOzY0W39jBkzHJIcixYtcjgcDkdOTo7DZrO5bbNt2zZHWFiYY/LkyYXe72uvveZaN3HiRLfPOjMz0yHJMWLECLfnu/XWWx2SHBMnTnStK+pzX716tUOS44033nCte++99xySHMuWLSu0fZcuXRxdunRx3Z42bZpDkuOtt95yrcvLy3N07NjRERkZ6cjKynJ7L2X97pYtW+aQ5HjvvffOuc2YMWMckhwrVqxwrTt+/LijYcOGjsTERNdnfv311ztatmx53tcr6xgAAG/ErnoA4OXCwsI0fPjwQuvDw8Nd148fP67Dhw/r8ssvV3Z2tn7++edin3fAgAGqUaOG6/bll18uydhNq7jH5efna/78+a51ixcv1tGjRzVgwADXuurVq+vbb7/V3r17i62lIKvVqoEDB2r16tVuu7/NmTNHMTExuuqqqyQZn0tQkPG/MZvNpj/++EORkZFq2rRpqXcFW7hwoSRp9OjRbuvHjBlTaNuCn3t+fr7++OMPXXTRRapevXqZd0FbuHChYmNjNWjQINe6kJAQjR49WidOnNCXX37ptn1Zv7uS1tKhQwdddtllrnWRkZG6++67tX37dm3atEmS8f3u3r37vLsIlnUMAIA3IjgBgJerV69ekc0EfvrpJ/Xr10/VqlVTdHS06tSp42oscezYsWKf94ILLnC77fwh/ueff573cUlJSWrWrJnmzp3rWjd37lzVrl1bV155pWvdk08+qR9//FEJCQnq0KGD0tLSSvzD3tn8wXm8zO7du7VixQoNHDhQVqtVkmS32/Wf//xHjRs3VlhYmGrXrq06derohx9+KNH7L2jHjh0KCgrShRde6La+adOmhbY9deqUUlNTlZCQ4Pa6R48eLfXrFnz9xo0bu4Kgk3PXvh07dritL+t3V9JainrfZ9fy4IMPKjIyUh06dFDjxo01cuRIrVy50u0x5RkDAOBtCE4A4OUKznA4HT16VF26dNGGDRs0efJkffzxx8rIyNATTzwhSSVqP+4MIGdzOBzFPnbAgAFatmyZDh8+rNzcXH300Ue68cYb3TrV3XLLLdq6dauee+45xcfH66mnnlLLli312WefFfv87du3V7NmzfT2229Lkt5++205HA63bnqPPfaYxo4dqyuuuEJvvfWWFi1apIyMDLVs2bJS26//61//0qOPPqpbbrlF7777rhYvXqyMjAzVqlXLY23fy/PdVZTmzZtry5Yteuedd3TZZZfp/fff12WXXaaJEye6tinPGAAAb0NzCADwQcuXL9cff/yh+fPn64orrnCt37Ztm0def8CAAZo0aZLef/99xcTEKCsrSwMHDiy0XVxcnEaMGKERI0bo4MGDateunR599FH17t272NcYPHiwUlJS9MMPP2jOnDlq3LixLrnkEtf98+bNU7du3fTKK6+4Pe7o0aOqXbt2qd5PgwYNZLfb9fvvv7vNtmzZsqXQtvPmzdPQoUP1zDPPuNbl5OTo6NGjbtud3bWvuNf/4YcfZLfb3WadnLtcNmjQoMTPVV4NGjQo8n0XVUvVqlU1YMAADRgwQHl5eerfv78effRRjR8/XlWqVJFUvjEAAN6EGScA8EHOGYeCMwx5eXmaPn26R16/efPmatWqlebOnau5c+cqLi7OLcDZbLZCu63VrVtX8fHxys3NLdFrOGeXUlNTlZmZWejcTVartdAMy3vvvac9e/aU+v04f8Q/++yzbuunTZtWaNuiXve5554r1Aa+atWqklQoUBWlT58+2r9/v9vuj6dPn9Zzzz2nyMhIdenSpSRvo0L06dNHa9as0erVq13rTp48qZdfflmJiYlq0aKFJKPbY0GhoaFq0aKFHA6H8vPzK2QMAIA3YcYJAHxQp06dVKNGDQ0dOlSjR4+WxWLRm2++6dFdtQYMGKDU1FRVqVJFd9xxh9tMyfHjx1W/fn3ddNNNSkpKUmRkpJYsWaK1a9e6zdScT8OGDdWpUyd9+OGHklQoOF177bWaPHmyhg8frk6dOmnjxo2aPXu2GjVqVOr30qZNGw0aNEjTp0/XsWPH1KlTJy1dulS//fZboW2vvfZavfnmm6pWrZpatGih1atXa8mSJapVq1ah57RarXriiSd07NgxhYWF6corr1TdunULPefdd9+tl156ScOGDdN3332nxMREzZs3TytXrtS0adMUFRVV6vd0Pu+//36RDUSGDh2qcePG6e2331bv3r01evRo1axZU6+//rq2bdum999/3/U99+zZU7GxsercubNiYmK0efNmPf/887rmmmsUFRWlo0ePlnsMAIA3ITgBgA+qVauWPvnkE91///2aMGGCatSoodtuu01XXXWV6zxKlW3AgAGaMGGCsrOz3brpSVJERIRGjBihxYsXa/78+bLb7brooos0ffp0/fOf/yzxawwePFirVq1Shw4ddNFFF7nd99BDD+nkyZOaM2eO5s6dq3bt2unTTz/VuHHjyvR+Xn31VdWpU0ezZ8/WBx98oCuvvFKffvqpEhIS3Lb773//K6vVqtmzZysnJ0edO3fWkiVLCn3usbGxmjFjhqZMmaI77rhDNptNy5YtKzI4hYeHa/ny5Ro3bpxef/11ZWVlqWnTpnrttdc0bNiwMr2f83nnnXeKXN+1a1dddtllWrVqlR588EE999xzysnJUevWrfXxxx+7ndfqH//4h2bPnq2pU6fqxIkTql+/vkaPHq0JEyZIqrgxAADewuLw5J8nAQAAAMAHcYwTAAAAABSD4AQAAAAAxSA4AQAAAEAxCE4AAAAAUAyCEwAAAAAUg+AEAAAAAMUIuPM42e127d27V1FRUbJYLGaXAwAAAMAkDodDx48fV3x8vNuJ3IsScMFp7969hU5mCAAAACBw7dq1S/Xr1z/vNgEXnKKioiQZH050dLTJ1aCs8vPztXjxYvXs2VMhISFmlwM/x3iDpzHm4EmMN3iaN425rKwsJSQkuDLC+QRccHLunhcdHU1w8mH5+fmKiIhQdHS06f/g4P8Yb/A0xhw8ifEGT/PGMVeSQ3hoDgEAAAAAxSA4AQAAAEAxCE4AAAAAUIyAO8YJAAAA3sfhcOj06dOy2Wxml4JKlp+fr+DgYOXk5Hjk+w4JCZHVai338xCcAAAAYKq8vDzt27dP2dnZZpcCD3A4HIqNjdWuXbs8cl5Vi8Wi+vXrKzIyslzPQ3ACAACAaex2u7Zt2yar1ar4+HiFhoZ65Mc0zGO323XixAlFRkYWe9LZ8nI4HDp06JB2796txo0bl2vmieAEAAAA0+Tl5clutyshIUERERFmlwMPsNvtysvLU5UqVSo9OElSnTp1tH37duXn55crONEcAgAAAKbzxA9oBKaKmsFkhAIAAABAMQhOAAAAAFAMghMAAAB8ns0mLV8uvf22cemLXc0TExM1bdo0s8vAORCcAAAA4NPmz5cSE6Vu3aRbbzUuExON9ZXBYrGcd0lLSyvT865du1Z33313uWrr2rWrxowZU67nQNHoqgcAAACfNX++dNNNksPhvn7PHmP9vHlS//4V+5r79u1zXZ87d65SU1O1ZcsW17qC5wtyOByy2WwKDi7+Z3edOnUqtlBUKGacTOQPU8oAAAAVyeGQTp4s2ZKVJY0eXTg0OZ9Hku6919iuJM9X1PMUJTY21rVUq1ZNFovFdfvnn39WVFSUPvvsM7Vv315hYWH6+uuv9fvvv+v6669XTEyMIiMjdckll2jJkiVuz3v2rnoWi0X/+9//1K9fP0VERKhx48b66KOPyvjJGt5//321bNlSYWFhSkxM1DPPPON2//Tp09W4cWNVqVJFMTExuummm1z3zZs3T61atVJ4eLhq1aql7t276+TJk+Wqx5cw42SS+fONf8i7d59ZV7++9N//VvxfRQAAAHxFdrZUYMKmXBwO47dWtWol2/7ECalq1Yp57XHjxunpp59Wo0aNVKNGDe3atUt9+vTRo48+qrCwML3xxhvq27evtmzZogsuuOCczzNp0iQ9+eSTeuqpp/Tcc89p8ODB2rFjh2rWrFnqmr777jvdcsstSktL04ABA7Rq1SqNGDFCtWrV0rBhw7Ru3TqNHj1ab775pjp16qQjR45oxYoVkoxZtkGDBunJJ59Uv379dPz4ca1YsUKOkqZNP0BwMoEZU8oAAADwnMmTJ6tHjx6u2zVr1lRSUpLrdnp6uhYsWKCPPvpIo0aNOufzDBs2TIMGDZIkPfbYY3r22We1Zs0aXX311aWuaerUqbrqqquUkpIiSWrSpIk2bdqkp556SsOGDdPOnTtVtWpVXXvttYqKilKDBg3Utm1bSUZwOn36tPr3768GDRpIklq1alXqGnwZu+p5mM1mzDSdb0p5zBh22wMAAIEpIsKY+SnJsnBhyZ5z4cKSPV9ERMW9j+TkZLfbJ06c0AMPPKDmzZurevXqioyM1ObNm7Vz587zPk/r1q1d16tWraro6GgdPHiwTDVt3rxZnTt3dlvXuXNn/frrr7LZbOrRo4caNGigRo0a6fbbb9fs2bOVnZ0tSUpKStJVV12lVq1a6eabb9bMmTP1559/lqkOX0Vw8rAVK9x3zzubwyHt2mVsBwAAEGgsFmN3uZIsPXsahzpYLOd+roQEY7uSPN+5nqcsqp61z98DDzygBQsW6LHHHtOKFSuUmZmpVq1aKS8v77zPExISctZ7sshut1dcoQVERUVp/fr1evvttxUXF6fU1FQlJSXp6NGjslqtysjI0GeffaYWLVroueeeU9OmTbVt27ZKqcUbEZw8rEATlgrZDgAAIFBZrcbx4VLh0OO8PW2asZ3ZVq5cqWHDhqlfv35q1aqVYmNjtX37do/W0Lx5c61cubJQXU2aNJH1rw8pODhY3bt315NPPqkffvhB27dv1xdffCHJCG2dO3fWpEmT9P333ys0NFQLFizw6HswE8c4eVhcXMVuBwAAEMj69zeODy+q6da0ad5z3Hjjxo01f/589e3bVxaLRSkpKZU2c3To0CFlZma6rYuLi9P999+vSy65ROnp6RowYIBWr16t559/XtOnT5ckffLJJ9q6dauuuOIK1ahRQwsXLpTdblfTpk317bffaunSperZs6fq1q2rb7/9VocOHVLz5s0r5T14I4KTh11+ufEPec+eoo9zsliM+y+/3PO1AQAA+KL+/aXrrzcOddi3z/gD9OWXe8dMk9PUqVP197//XZ06dVLt2rX14IMPKisrq1Jea86cOZozZ47buvT0dE2YMEHvvvuuUlNTlZ6erri4OE2ePFnDhg2TJFWvXl3z589XWlqacnJy1LhxY7399ttq2bKlNm/erK+++krTpk1TVlaWGjRooGeeeUa9e/eulPfgjSyOQOohKCkrK0vVqlXTsWPHFB0dbUoNzq56knt4ck4p01WvePn5+Vq4cKH69OlTaN9foKIx3uBpjDl4ktnjLScnR9u2bVPDhg1VpUoVj78+PM9utysrK0vR0dEKCqr8I4fON8ZKkw04xskEzinlevXc19evT2gCAAAAvBHByST9+0vbt0v33WfcTk6Wtm0jNAEAAADeyNTg9NVXX6lv376Kj4+XxWLRBx98UOxjli9frnbt2iksLEwXXXSRZs2aVel1VharVfrrfGbatk3ywEwlAAAAgDIw9af6yZMnlZSUpBdeeKFE22/btk3XXHONunXrpszMTI0ZM0Z33nmnFi1aVMmVVp5WraTgYOmPP6Rizn8GAAAAwCSmdtXr3bt3qTpxzJgxQw0bNtQzzzwjyehF//XXX+s///mPevXqVVllVqoqVaSLL5YyM6XvvpMaNDC7IgAAAABn86l25KtXr1b37t3d1vXq1Utjxow552Nyc3OVm5vruu1s+5ifn6/8/PxKqbO02rWzKjMzSGvW2NS3b+X08/c3zu/OW75D+DfGGzyNMQdPMnu85efny+FwyG63V9p5jeBdnE29nd97ZbPb7XI4HMrPz3ed6NepNOPep4LT/v37FRMT47YuJiZGWVlZOnXqlMLDwws9ZsqUKZo0aVKh9YsXL1ZERESl1VoaoaGJkpK0aNEf6thxtdnl+JSMjAyzS0AAYbzB0xhz8CSzxltwcLBiY2N14sQJ5eXlmVIDzHH8+HGPvE5eXp5OnTqlr776SqdPn3a7Lzs7u8TP41PBqSzGjx+vsWPHum5nZWUpISFBPXv2NO08TmerW9eiGTOkXbvqqHfvPq7zOeHc8vPzlZGRoR49enCOE1Q6xhs8jTEHTzJ7vOXk5GjXrl2KjIzkPE4BwuFw6Pjx44qKipLFAz98c3JyFB4eriuuuKLI8ziVlE8Fp9jYWB04cMBt3YEDBxQdHV3kbJMkhYWFKSwsrND6kJAQr/mfUdu2zgYRFu3bF8JxTqXgTd8j/B/jDZ7GmIMnmTXebDabLBaLgoKCPHIyVJjPuXue83uvbEFBQbJYLEWO8dKMeZ8anR07dtTSpUvd1mVkZKhjx44mVVQxnA0iJKNBBAAAAPxf165d3Y7VT0xM1LRp0877mJKewqc4FfU8gcTU4HTixAllZmYqMzNTktFuPDMzUzv/6ss9fvx4DRkyxLX9Pffco61bt+rf//63fv75Z02fPl3vvvuu7nOeRdaHtW9vXBKcAAAASiEtTUpPL/q+9HTj/grWt29fXX311UXet2LFClksFv3www+lft61a9fq7rvvLm95btLS0tSmTZtC6/ft21eq7tZlMWvWLFWvXr1SX8OTTA1O69atU9u2bdW2bVtJ0tixY9W2bVulpqZKMr7QnQVObtSwYUN9+umnysjIUFJSkp555hn973//89lW5AURnAAAAMrAapVSUwuHp/R0Y/1ZXdQqwh133KGMjAzt3r270H2vvfaakpOT1bp161I/b506dTzWvCw2NrbIw1lwbqYGp65du8rhcBRaZs2aJclIqcuXLy/0mO+//165ubn6/fffNWzYMI/XXRkKBqe/OjQCAAAEHodDOnmy5MvYsdKECUZISkkx1qWkGLcnTDDuL+lzlfBH2LXXXqs6deq4frM6nThxQu+9957uuOMO/fHHHxo0aJDq1auniIgItWrVSm+//fZ5n/fsXfV+/fVXV0ODFi1aFNn58MEHH1STJk0UERGhRo0aKSUlxdVie9asWZo0aZI2bNggi8Uii8XiqvnsXfU2btyoK6+8UuHh4apVq5buvvtunThxwnX/sGHDdMMNN+jpp59WXFycatWqpZEjR5arjf3OnTt1/fXXKzIyUtHR0brlllvc+hls2LBB3bp1U1RUlKKjo9W+fXutW7dOkrRjxw717dtXNWrUUNWqVdWyZUstXLiwzLWUhE81h/BnrVsbDSIOH5Z27ZIuuMDsigAAAEyQnS1FRpbtsY88Yiznul2cEyekqlWL3Sw4OFhDhgzRrFmz9PDDD7s6w7333nuy2WwaNGiQTpw4ofbt2+vBBx9UdHS0Pv30U91+++268MIL1aFDh2Jfw263q3///oqJidG3336rY8eOFXnu0qioKM2aNUvx8fHauHGj7rrrLkVFRenf//63BgwYoB9//FGff/65lixZIkmqVq1aoec4efKkevXqpY4dO2rt2rU6ePCg7rzzTo0aNcotHC5btkxxcXFatmyZfvvtNw0YMEBt2rTRXXfdVez7Ker99evXT5GRkfryyy91+vRpjRw5UgMGDHBNnAwePFht27bViy++KKvVqszMTFczh5EjRyovL09fffWVqlatqk2bNimyrOOmhAhOXsLZICIz05h1IjgBAAB4r7///e966qmn9OWXX6pr166SjN30brzxRlWrVk3VqlXTAw884Nr+X//6lxYtWqR33323RMFpyZIl+vnnn7Vo0SLFx8dLkh577LFCxyVNmDDBdT0xMVEPPPCA3nnnHf373/9WeHi4IiMjXefKOpc5c+YoJydHb7zxhqr+FRyff/559e3bV0888YTrPKo1atTQ888/L6vVqmbNmumaa67R0qVLyxScvvzyS23cuFHbtm1TQkKCJOmNN95Qy5YttXbtWl1yySXauXOn/u///k/NmjWTJDVu3Nj1+J07d+rGG29Uq1atJEmNGjUqdQ2l5VNd9fydc3e9v2YgAQAAAk9EhDHzU9rFGSBCQ43LCRNK/xylOL6oWbNm6tSpk1599VVJ0m+//aYVK1bojjvukGS0WU9PT1erVq1Us2ZNRUZGatGiRW7H75/P5s2blZCQ4ApNkorsJD137lx17txZsbGxioyM1IQJE0r8GgVfKykpyRWaJKlz586y2+3asmWLa13Lli1lLXDMWFxcnA4ePFiq13L65ZdflJCQ4ApNktSiRQtVr15dmzdvlmT0P7jzzjvVvXt3Pf744/r9999d244ePVqPPPKIOnfurIkTJ5apGUdpEZy8CA0iAABAwLNYjN3lSrNMnWrskjd5spSba1w+8oixvjTPU8qTsd5xxx16//33dfz4cb322mu68MIL1aVLF0nSU089pf/+97968MEHtWzZMmVmZqpXr17Ky8ursI9q9erVGjx4sPr06aNPPvlE33//vR5++OEKfY2Czj7nkcVicZ2TqTKkpaXpp59+0jXXXKMvvvhCLVq00IIFCyRJd955p7Zu3arbb79dGzduVHJysp577rlKq0UiOHkVGkQAAACUkrN73uTJRlMIybicPLnobnsV6JZbblFQUJDmzJmjN954Q3//+99dxzutXLlS119/vW677TYlJSWpUaNG+uWXX0r83M2bN9euXbu0b98+17pvvvnGbZtVq1apQYMGevjhh5WcnKzGjRtrx44dbtuEhobKZrMV+1obNmzQyZMnXetWrlypoKAgNW3atMQ1l0aTJk20a9cu7dq1y7Vu06ZNOnr0qFq0aOG23X333afFixerf//+eu2111z3JSQk6J577tH8+fN1//33a+bMmZVSqxPByYuc3SACAAAAxbDZ3EOTkzM8FRMayiMyMlIDBgzQ+PHjtW/fPrduz40bN1ZGRoZWrVqlzZs36x//+Idbx7jidO/eXU2aNNHQoUO1YcMGrVixQg8//LDbNo0bN9bOnTv1zjvv6Pfff9ezzz7rmpFxSkxMdJ0r9fDhw8rNzS30WoMHD1aVKlU0dOhQ/fjjj1q2bJn+9a9/6fbbb3cd31RWNpvNdd5W57J582Z17dpVrVq10uDBg7V+/XqtWbNGQ4YMUZcuXZScnKxTp05p1KhRWr58uXbs2KGVK1dq7dq1at68uSRpzJgxWrRokbZt26b169dr2bJlrvsqC8HJi1SpIrVsaVxndz0AAIASSEsrHJqcUlIq5QS4Bd1xxx36888/1atXL7fjkSZMmKB27dqpV69e6tq1q2JjY3XDDTeU+HmDgoK0YMECnTp1Sh06dNCdd96pRx991G2b6667Tvfdd59GjRqlNm3aaNWqVUo567O48cYbdfXVV6tbt26qU6dOkS3RIyIitGjRIh05ckSXXHKJbrrpJl111VV6/vnnS/dhFOHEiROu87Y6l+uvv14Wi0ULFixQjRo1dMUVV6h79+5q1KiR5s6dK0myWq36448/NGTIEDVp0kS33HKLevfurUmTJkkyAtnIkSPVvHlzXX311WrSpImmT59e7nrPx+JwBNZOYVlZWapWrZqOHTum6Ohos8sp5I47pFdflR5+uHTdMwNNfn6+Fi5cqD59+hTa3xaoaIw3eBpjDp5k9njLycnRtm3b1LBhQ1WpUsXjrw/Ps9vtysrKUnR0tIKCKn8e53xjrDTZgBknL0ODCAAAAMD7EJy8THKycUmDCAAAAMB7EJy8jLNBxKFD0u7dZlcDAAAAQCI4eZ2CDSI4ES4AAADgHQhOXojjnAAAQKAJsH5l8KCKGlsEJy9EcAIAAIHC2ckvOzvb5Ergr/Ly8iQZLc7LI7giikHFKhicHA7prxNQAwAA+B2r1arq1avr4MGDkoxzCln48ePX7Ha78vLylJOTU+ntyO12uw4dOqSIiAgFB5cv+hCcvFDr1pLVeqZBREKC2RUBAABUntjYWElyhSf4N4fDoVOnTik8PNwjITkoKEgXXHBBuV+L4OSFwsONBhE//GDMOhGcAACAP7NYLIqLi1PdunWVn59vdjmoZPn5+frqq690xRVXeOSky6GhoRUys0Vw8lLt258JTjfcYHY1AAAAlc9qtZb7OBR4P6vVqtOnT6tKlSoeCU4VheYQXqrgiXABAAAAmIvg5KXObhABAAAAwDwEJy/lbBBx8KDRIAIAAACAeQhOXsrZIEJidz0AAADAbAQnL8aJcAEAAADvQHDyYgQnAAAAwDsQnLwYDSIAAAAA70Bw8mJJSWcaROzZY3Y1AAAAQOAiOHmx8HCpRQvjOrvrAQAAAOYhOHk5ToQLAAAAmI/g5OWcxzmtW2duHQAAAEAgIzh5ORpEAAAAAOYjOHk5GkQAAAAA5iM4eTkaRAAAAADmIzj5AE6ECwAAAJiL4OQDCE4AAACAuQhOPoAGEQAAAIC5CE4+wNkg4sABae9es6sBAAAAAg/ByQdERNAgAgAAADATwclHcCJcAAAAwDwEJx9BgwgAAADAPAQnH0GDCAAAAMA8BCcfkZQkBQXRIAIAAAAwA8HJR9AgAgAAADAPwcmHcJwTAAAAYA6Ckw8hOAEAAADmIDj5kORk45LgBAAAAHgWwcmHOBtE7N9PgwgAAADAkwhOPqRggwhOhAsAAAB4DsHJx3CcEwAAAOB5BCcfQ3ACAAAAPI/g5GMITgAAAIDnEZx8TJs2NIgAAAAAPI3g5GMiIqTmzY3rzDoBAAAAnkFw8kHsrgcAAAB4FsHJB3EiXAAAAMCzCE4+iBknAAAAwLMITj7I2SBi3z4aRAAAAACeQHDyQTSIAAAAADyL4OSj2F0PAAAA8ByCk48iOAEAAACeQ3DyUQQnAAAAwHMITj6qYIOIffvMrgYAAADwbwQnH1W1qtSsmXGdWScAAACgchGcfBgnwgUAAAA8g+Dkw5zHOa1bZ24dAAAAgL8jOPkwGkQAAAAAnkFw8mE0iAAAAAA8g+Dkw2gQAQAAAHgGwcnHsbseAAAAUPkITj6O4AQAAABUPoKTjyM4AQAAAJWP4OTjnA0i9u6V9u83uxoAAADAPxGcfFxkJA0iAAAAgMpGcPIDnAgXAAAAqFwEJz/AcU4AAABA5SI4+QGCEwAAAFC5CE5+oE0byWKhQQQAAABQWQhOfoAGEQAAAEDlMj04vfDCC0pMTFSVKlV06aWXas2aNefdftq0aWratKnCw8OVkJCg++67Tzk5OR6q1nuxux4AAABQeUwNTnPnztXYsWM1ceJErV+/XklJSerVq5cOHjxY5PZz5szRuHHjNHHiRG3evFmvvPKK5s6dq4ceesjDlXsfghMAAABQeUwNTlOnTtVdd92l4cOHq0WLFpoxY4YiIiL06quvFrn9qlWr1LlzZ916661KTExUz549NWjQoGJnqQJBcrJxSXACAAAAKl6wWS+cl5en7777TuPHj3etCwoKUvfu3bV69eoiH9OpUye99dZbWrNmjTp06KCtW7dq4cKFuv3228/5Orm5ucrNzXXdzsrKkiTl5+crPz+/gt6N+Vq2lCyWYO3ZY9GuXfmKjTW7osrl/O786TuE92K8wdMYc/Akxhs8zZvGXGlqMC04HT58WDabTTExMW7rY2Ji9PPPPxf5mFtvvVWHDx/WZZddJofDodOnT+uee+457656U6ZM0aRJkwqtX7x4sSIiIsr3JrxMvXpXavfuKL388ndKTj5gdjkekZGRYXYJCCCMN3gaYw6exHiDp3nDmMvOzi7xtqYFp7JYvny5HnvsMU2fPl2XXnqpfvvtN917771KT09XSkpKkY8ZP368xo4d67qdlZWlhIQE9ezZU9HR0Z4q3SOuuMKqOXOkoKBL1KeP3exyKlV+fr4yMjLUo0cPhYSEmF0O/BzjDZ7GmIMnMd7gad405px7o5WEacGpdu3aslqtOnDAfWbkwIEDij3HfmYpKSm6/fbbdeedd0qSWrVqpZMnT+ruu+/Www8/rKCgwodshYWFKSwsrND6kJAQ07+oinbJJdKcOVJmplUhIVazy/EIf/we4b0Yb/A0xhw8ifEGT/OGMVea1zetOURoaKjat2+vpUuXutbZ7XYtXbpUHTt2LPIx2dnZhcKR1WoEBIfDUXnF+gg66wEAAACVw9Rd9caOHauhQ4cqOTlZHTp00LRp03Ty5EkNHz5ckjRkyBDVq1dPU6ZMkST17dtXU6dOVdu2bV276qWkpKhv376uABXI2raVLBZpzx7pwAHprMPHAAAAAJSRqcFpwIABOnTokFJTU7V//361adNGn3/+uathxM6dO91mmCZMmCCLxaIJEyZoz549qlOnjvr27atHH33UrLfgVSIjpaZNpZ9/Nmad+vQxuyIAAADAP5jeHGLUqFEaNWpUkfctX77c7XZwcLAmTpyoiRMneqAy39S+PcEJAAAAqGimngAXFY8T4QIAAAAVj+DkZ2gQAQAAAFQ8gpOfcTaI2L3baBABAAAAoPwITn7G2SBCYtYJAAAAqCgEJz/E7noAAABAxSI4+SGCEwAAAFCxCE5+iOAEAAAAVCyCkx8q2CDi4EGzqwEAAAB8H8HJD0VF0SACAAAAqEgEJz/F7noAAABAxSE4+SlncFq3ztw6AAAAAH9AcPJTzDgBAAAAFYfg5KdoEAEAAABUHIKTn4qKkpo0Ma4z6wQAAACUD8HJj7G7HgAAAFAxCE5+jOAEAAAAVAyCkx8jOAEAAAAVg+Dkx5wNInbtkg4dMrsaAAAAwHcRnPxYdDQNIgAAAICKQHDyc5wIFwAAACg/gpOf4zgnAAAAoPwITn6O4AQAAACUH8HJz7Vta1zSIAIAAAAoO4KTn6NBBAAAAFB+BKcAwO56AAAAQPkQnAIAwQkAAAAoH4JTAEhONi4JTgAAAEDZEJwCgLNBxM6dNIgAAAAAyoLgFABoEAEAAACUD8EpQHCcEwAAAFB2BKcAQXACAAAAyo7gFCAITgAAAEDZEZwCRMEGEYcPm1sLAAAA4GsITgGiWjWpcWPjOrNOAAAAQOkQnAII53MCAAAAyobgFEA4zgkAAAAoG4JTACE4AQAAAGVDcAogzgYRO3bQIAIAAAAoDYJTAKFBBAAAAFA2BKcAw+56AAAAQOkRnAIMwQkAAAAoPYJTgCE4AQAAAKVHcAow7doZlzt2SH/8YW4tAAAAgK8gOAUYGkQAAAAApUdwCkDsrgcAAACUDsEpADmD07p15tYBAAAA+AqCUwBixgkAAAAoHYJTAKJBBAAAAFA6BKcAVK2adNFFxnVmnQAAAIDiEZwCFLvrAQAAACVHcApQBCcAAACg5AhOAYrgBAAAAJQcwSlAORtEbN9OgwgAAACgOASnAFW9+pkGEevXm1oKAAAA4PUITgGME+ECAAAAJUNwCmAc5wQAAACUDMEpgBGcAAAAgJIhOAUwGkQAAAAAJUNwCmDVq0sXXmhcp0EEAAAAcG4EpwDH7noAAABA8QhOAS452bgkOAEAAADnRnAKcMw4AQAAAMUjOAU4Z4OIbdukI0fMrQUAAADwVgSnAFewQQSzTgAAAEDRCE5gdz0AAACgGAQnEJwAAACAYhCcQHACAAAAikFwAg0iAAAAgGIQnKAaNaRGjYzr69ebWwsAAADgjQhOkMSJcAEAAIDzIThBEsc5AQAAAOdDcIKkM8Fp3Tpz6wAAAAC8EcEJkmgQAQAAAJwPwQmSaBABAAAAnA/BCS4c5wQAAAAUjeAEF4ITAAAAUDSCE1wITgAAAEDRTA9OL7zwghITE1WlShVdeumlWrNmzXm3P3r0qEaOHKm4uDiFhYWpSZMmWrhwoYeq9W/OBhFbt0p//mluLQAAAIA3MTU4zZ07V2PHjtXEiRO1fv16JSUlqVevXjp48GCR2+fl5alHjx7avn275s2bpy1btmjmzJmqV6+ehyv3TzVr0iACAAAAKIqpwWnq1Km66667NHz4cLVo0UIzZsxQRESEXn311SK3f/XVV3XkyBF98MEH6ty5sxITE9WlSxclJSV5uHL/xe56AAAAQGHBZr1wXl6evvvuO40fP961LigoSN27d9fq1auLfMxHH32kjh07auTIkfrwww9Vp04d3XrrrXrwwQdltVqLfExubq5yc3Ndt7OysiRJ+fn5ys/Pr8B35B/atAnSe+9ZtWaNXfn5NrPLOSfnd8d3CE9gvMHTGHPwJMYbPM2bxlxpajAtOB0+fFg2m00xMTFu62NiYvTzzz8X+ZitW7fqiy++0ODBg7Vw4UL99ttvGjFihPLz8zVx4sQiHzNlyhRNmjSp0PrFixcrIiKi/G/Ez5w+XUdSJ3399SktXLjE7HKKlZGRYXYJCCCMN3gaYw6exHiDp3nDmMvOzi7xthaHw+GoxFrOae/evapXr55WrVqljh07utb/+9//1pdffqlvv/220GOaNGminJwcbdu2zTXDNHXqVD311FPat29fka9T1IxTQkKCDh8+rOjo6Ap+V77vyBEpNjZEknTgQL5q1DC5oHPIz89XRkaGevTooZCQELPLgZ9jvMHTGHPwJMYbPM2bxlxWVpZq166tY8eOFZsNTJtxql27tqxWqw4cOOC2/sCBA4qNjS3yMXFxcQoJCXHbLa958+bav3+/8vLyFBoaWugxYWFhCgsLK7Q+JCTE9C/KG8XESA0bStu2SRs3huiqq8yu6Pz4HuFJjDd4GmMOnsR4g6d5w5grzeub1hwiNDRU7du319KlS13r7Ha7li5d6jYDVVDnzp3122+/yW63u9b98ssviouLKzI0oWxoEAEAAAC4M7Wr3tixYzVz5ky9/vrr2rx5s/75z3/q5MmTGj58uCRpyJAhbs0j/vnPf+rIkSO699579csvv+jTTz/VY489ppEjR5r1FvwSwQkAAABwZ9quepI0YMAAHTp0SKmpqdq/f7/atGmjzz//3NUwYufOnQoKOpPtEhIStGjRIt13331q3bq16tWrp3vvvVcPPvigWW/BLxGcAAAAAHemBidJGjVqlEaNGlXkfcuXLy+0rmPHjvrmm28quarA5gxOv/8uHT0qVa9uZjUAAACA+UzdVQ/eqWZNo0GEJK1fb24tAAAAgDcgOKFIzlmndevMrQMAAADwBgQnFInjnAAAAIAzCE4oEsEJAAAAOIPghCK1a2dcOhtEAAAAAIGsTMFp165d2r17t+v2mjVrNGbMGL388ssVVhjMVauWlJhoXKdBBAAAAAJdmYLTrbfeqmXLlkmS9u/frx49emjNmjV6+OGHNXny5AotEOZhdz0AAADAUKbg9OOPP6pDhw6SpHfffVcXX3yxVq1apdmzZ2vWrFkVWR9MlJxsXBKcAAAAEOjKFJzy8/MVFhYmSVqyZImuu+46SVKzZs20b9++iqsOpmLGCQAAADCUKTi1bNlSM2bM0IoVK5SRkaGrr75akrR3717VqlWrQguEeZwNIn77jQYRAAAACGxlCk5PPPGEXnrpJXXt2lWDBg1SUlKSJOmjjz5y7cIH30eDCAAAAMAQXJYHde3aVYcPH1ZWVpZq1KjhWn/33XcrIiKiwoqD+dq3l7ZvN3bXu/JKs6sBAAAAzFGmGadTp04pNzfXFZp27NihadOmacuWLapbt26FFghzcZwTAAAAUMbgdP311+uNN96QJB09elSXXnqpnnnmGd1www168cUXK7RAmIvgBAAAAJQxOK1fv16XX365JGnevHmKiYnRjh079MYbb+jZZ5+t0AJhLmdw+u036dgxc2sBAAAAzFKm4JSdna2oqChJ0uLFi9W/f38FBQXpb3/7m3bs2FGhBcJctWpJDRoY12kQAQAAgEBVpuB00UUX6YMPPtCuXbu0aNEi9ezZU5J08OBBRUdHV2iBMB8nwgUAAECgK1NwSk1N1QMPPKDExER16NBBHTt2lGTMPrVt27ZCC4T5OM4JAAAAga5M7chvuukmXXbZZdq3b5/rHE6SdNVVV6lfv34VVhy8gzM4rVtnbh0AAACAWcoUnCQpNjZWsbGx2r17tySpfv36nPzWT53dIKJaNXPrAQAAADytTLvq2e12TZ48WdWqVVODBg3UoEEDVa9eXenp6bLb7RVdI0xGgwgAAAAEujLNOD388MN65ZVX9Pjjj6tz586SpK+//lppaWnKycnRo48+WqFFwnzt20s7dhjHOXXrZnY1AAAAgGeVKTi9/vrr+t///qfrrrvOta5169aqV6+eRowYQXDyQ+3bS/Pn0yACAAAAgalMu+odOXJEzZo1K7S+WbNmOnLkSLmLgvehsx4AAAACWZmCU1JSkp5//vlC659//nm1bt263EXB+ziD06+/Gg0iAAAAgEBSpl31nnzySV1zzTVasmSJ6xxOq1ev1q5du7Rw4cIKLRDeoXZto0HEjh3S999LXbuaXREAAADgOWWacerSpYt++eUX9evXT0ePHtXRo0fVv39//fTTT3rzzTcrukZ4CXbXAwAAQKAq83mc4uPjCzWB2LBhg1555RW9/PLL5S4M3sfZIIIT4QIAACDQlGnGCYGJGScAAAAEKoITSowGEQAAAAhUBCeUWO3a0gUXGNe//97cWgAAAABPKtUxTv379z/v/UePHi1PLfAB7dtLO3cau+vRWQ8AAACBolTBqVq1asXeP2TIkHIVBO/Wvr20YAHHOQEAACCwlCo4vfbaa5VVB3xEcrJxSXACAABAIOEYJ5SKs0HEL79IWVnm1gIAAAB4CsEJpUKDCAAAAAQighNKzTnrxIlwAQAAECgITig1ToQLAACAQENwQqkRnAAAABBoCE4oNRpEAAAAINAQnFBqdepICQnGdRpEAAAAIBAQnFAm7K4HAACAQEJwQplwIlwAAAAEEoITyoQZJwAAAAQSghPKhAYRAAAACCQEJ5SJs0GEw0GDCAAAAPg/ghPKjN31AAAAECgITigzghMAAAACBcEJZUZwAgAAQKAgOKHMCjaIOH7c3FoAAACAykRwQpnVrSvVr0+DCAAAAPg/ghPKhRPhAgAAIBAQnFAuHOcEAACAQEBwQrk4g9O6debWAQAAAFQmghPKhQYRAAAACAQEJ5QLDSIAAAAQCAhOKDeOcwIAAIC/Izih3AhOAAAA8HcEJ5QbwQkAAAD+juCEcnMGpy1baBABAAAA/0RwQrnFxJxpEJGZaXY1AAAAQMUjOKFCsLseAAAA/BnBCRWCE+ECAADAnxGcUCGYcQIAAIA/IzihQtAgAgAAAP6M4IQKERMj1atHgwgAAAD4J4ITKgy76wEAAMBfEZxQYQhOAAAA8FcEJ1SY5GTjkuAEAAAAf0NwQoVxzjj9/LN04oS5tQAAAAAVieCECkODCAAAAPgrghMqFCfCBQAAgD8iOKFC0SACAAAA/ojghApFcAIAAIA/IjihQtEgAgAAAP6I4IQKFRsrxcfTIAIAAAD+heCECsfuegAAAPA3XhGcXnjhBSUmJqpKlSq69NJLtWbNmhI97p133pHFYtENN9xQuQWiVDgRLgAAAPyN6cFp7ty5Gjt2rCZOnKj169crKSlJvXr10sGDB8/7uO3bt+uBBx7Q5Zdf7qFKUVLMOAEAAMDfmB6cpk6dqrvuukvDhw9XixYtNGPGDEVEROjVV18952NsNpsGDx6sSZMmqVGjRh6sFiVBgwgAAAD4m2AzXzwvL0/fffedxo8f71oXFBSk7t27a/Xq1ed83OTJk1W3bl3dcccdWrFixXlfIzc3V7m5ua7bWVlZkqT8/Hzl5+eX8x2gKLVqSfHxwdq716J1606rc2dHhb+G87vjO4QnMN7gaYw5eBLjDZ7mTWOuNDWYGpwOHz4sm82mmJgYt/UxMTH6+eefi3zM119/rVdeeUWZJWzZNmXKFE2aNKnQ+sWLFysiIqLUNaNk6tXroL174/TWW5t17NjWSnudjIyMSntu4GyMN3gaYw6exHiDp3nDmMvOzi7xtqYGp9I6fvy4br/9ds2cOVO1a9cu0WPGjx+vsWPHum5nZWUpISFBPXv2VHR0dGWVGvC++y5Ia9dKOTkt1adPswp//vz8fGVkZKhHjx4KCQmp8OcHCmK8wdMYc/Akxhs8zZvGnHNvtJIwNTjVrl1bVqtVBw4ccFt/4MABxcbGFtr+999/1/bt29W3b1/XOrvdLkkKDg7Wli1bdOGFF7o9JiwsTGFhYYWeKyQkxPQvyp916GBcfv99kEJCKu9QOr5HeBLjDZ7GmIMnMd7gad4w5krz+qY2hwgNDVX79u21dOlS1zq73a6lS5eqY8eOhbZv1qyZNm7cqMzMTNdy3XXXqVu3bsrMzFRCQoIny8d5FGwQcfKkubUAAAAA5WX6rnpjx47V0KFDlZycrA4dOmjatGk6efKkhg8fLkkaMmSI6tWrpylTpqhKlSq6+OKL3R5fvXp1SSq0HuaKi5Pi46W9e6XMTKlzZ7MrAgAAAMrO9OA0YMAAHTp0SKmpqdq/f7/atGmjzz//3NUwYufOnQoKMr1rOsqgfXsjOH33HcEJAAAAvs304CRJo0aN0qhRo4q8b/ny5ed97KxZsyq+IFSI9u2ljz/mRLgAAADwfUzloNI4j3Nat87cOgAAAIDyIjih0tAgAgAAAP6C4IRKExdnLHa70SACAAAA8FUEJ1Qq56wTxzkBAADAlxGcUKkITgAAAPAHBCdUKoITAAAA/AHBCZXKGZw2b6ZBBAAAAHwXwQmVKj7+TIOIDRvMrgYAAAAoG4ITKh276wEAAMDXEZxQ6TgRLgAAAHwdwQmVjhknAAAA+DqCEyodDSIAAADg6whOqHTx8VJsLA0iAAAA4LsITvAIdtcDAACALyM4wSMITgAAAPBlBCd4RHKycUlwAgAAgC8iOMEjnDNOmzZJ2dnm1gIAAACUFsEJHkGDCAAAAPgyghM8hhPhAgAAwFcRnOAxNIgAAACAryI4wWMITgAAAPBVBCd4DA0iAAAA4KsITvCY+HgpJoYGEQAAAPA9BCd4jMXC7noAAADwTQQneBQnwgUAAIAvIjjBo5hxAgAAgC8iOMGjaBABAAAAX0Rwgkc5G0TYbDSIAAAAgO8gOMGjaBABAAAAX0RwgscRnAAAAOBrCE7wOIITAAAAfA3BCR5XsEHEqVPm1gIAAACUBMEJHlevHg0iAAAA4FsITvA4GkQAAADA1xCcYAqCEwAAAHwJwQmmcAandevMrQMAAAAoCYITTEGDCAAAAPgSghNMUa+eVLcuDSIAAADgGwhOMAUNIgAAAOBLCE4wDcEJAAAAvoLgBNMQnAAAAOArCE4wTXKycfnTTzSIAAAAgHcjOME0BRtE/PCD2dUAAAAA50ZwgmloEAEAAABfQXCCqTgRLgAAAHwBwQmmYsYJAAAAvoDgBFM5gxMNIgAAAODNCE4wVf36Up06NIgAAACAdyM4wVQ0iAAAAIAvIDjBdAQnAAAAeDuCE0znPBEuwQkAAADeiuAE0xVsEJGTY24tAAAAQFEITjCds0HE6dM0iAAAAIB3IjjBdAUbRHAiXAAAAHgjghO8Ag0iAAAA4M0ITvAKBCcAAAB4M4ITvAINIgAAAODNCE7wCgkJUu3aNIgAAACAdyI4wStYLJzPCQAAAN6L4ASvwXFOAAAA8FYEJ3gNghMAAAC8FcEJXsMZnH78kQYRAAAA8C4EJ3gNGkQAAADAWxGc4DUsFnbXAwAAgHciOMGrEJwAAADgjQhO8CoEJwAAAHgjghO8Cg0iAAAA4I0ITvAqF1xwpkHExo1mVwMAAAAYCE7wKjSIAAAAgDciOMHrEJwAAADgbQhO8DrO4LRunbl1AAAAAE4EJ3gdGkQAAADA2xCc4HUuuECqVYsGEQAAAPAeBCd4HRpEAAAAwNsQnOCVCE4AAADwJgQneCWCEwAAALwJwQleKTnZuPzxRyk319xaAAAAAK8ITi+88IISExNVpUoVXXrppVqzZs05t505c6Yuv/xy1ahRQzVq1FD37t3Puz18k7NBRH4+DSIAAABgPtOD09y5czV27FhNnDhR69evV1JSknr16qWDBw8Wuf3y5cs1aNAgLVu2TKtXr1ZCQoJ69uypPXv2eLhyVCYaRAAAAMCbmB6cpk6dqrvuukvDhw9XixYtNGPGDEVEROjVV18tcvvZs2drxIgRatOmjZo1a6b//e9/stvtWrp0qYcrR2XjRLgAAADwFsFmvnheXp6+++47jR8/3rUuKChI3bt31+rVq0v0HNnZ2crPz1fNmjWLvD83N1e5BQ6SycrKkiTl5+crPz+/HNWjsiUlWSQFa906h/LzT7vd5/zu+A7hCYw3eBpjDp7EeIOnedOYK00Npganw4cPy2azKSYmxm19TEyMfv755xI9x4MPPqj4+Hh17969yPunTJmiSZMmFVq/ePFiRURElL5oeMyxY+GSeurHHx368MPPFRJiL7RNRkaG5wtDwGK8wdMYc/Akxhs8zRvGXHZ2dom3NTU4ldfjjz+ud955R8uXL1eVKlWK3Gb8+PEaO3as63ZWVpbruKjo6GhPlYoycDik8eMdOnIkSPXr91b79g7Xffn5+crIyFCPHj0UEhJiYpUIBIw3eBpjDp7EeIOnedOYc+6NVhKmBqfatWvLarXqwIEDbusPHDig2NjY8z726aef1uOPP64lS5aodevW59wuLCxMYWFhhdaHhISY/kWheO3bSxkZ0oYNwfrb3wrfz/cIT2K8wdMYc/Akxhs8zRvGXGle39TmEKGhoWrfvr1bYwdno4eOHTue83FPPvmk0tPT9fnnnyvZecIf+CXn10tnPQAAAJjJ9F31xo4dq6FDhyo5OVkdOnTQtGnTdPLkSQ0fPlySNGTIENWrV09TpkyRJD3xxBNKTU3VnDlzlJiYqP3790uSIiMjFRkZadr7QOWgJTkAAAC8genBacCAATp06JBSU1O1f/9+tWnTRp9//rmrYcTOnTsVFHRmYuzFF19UXl6ebrrpJrfnmThxotLS0jxZOjzAGZw2bpRyc6Ui9roEAAAAKp3pwUmSRo0apVGjRhV53/Lly91ub9++vfILgtdo0ECqWVM6ckT68cczQQoAAADwJNNPgAucj8XCiXABAABgPoITvB7HOQEAAMBsBCd4PYITAAAAzEZwgtc7u0EEAAAA4GkEJ3i9xESpRg0pP99oEAEAAAB4GsEJXs9i4US4AAAAMBfBCT6B45wAAABgJoITfALBCQAAAGYiOMEnOIPTDz/QIAIAAACeR3CCT6BBBAAAAMxEcIJPsFjYXQ8AAADmITjBZxCcAAAAYBaCE3wGwQkAAABmITiZIS1NSk8v+r70dON+FOIMThs3Snl55tYCAACAwEJwMoPVKqWmFg5P6enGeqvVnLq8XMOGRoOIvDzpp5/MrgYAAACBJNjsAgJSSopxmZoq7dwpvfSS9Oijxu3Jk8/cDzfOBhFLlkjr11sUF2d2RQAAAAgUzDiZJSVF6t5d+t//zsxADRkijRtndmVezbm73vr1FnMLAQAAQEAhOJnpssvcb7/xhlS3rnT77dKCBVJ2tjl1ebEzDSIITgAAAPAcgpOZgv76+IP/2mOyalXp6FHprbek/v2l2rWNyzfflP7807QyvYkzOP3wg0XLltXXl19aZLOZWxMAAAD8H8HJLM5GEJMnS/n5xuXJk9Idd0hjx0qJidKpU8bM05AhxkxUz57Siy9K+/aZXb1pvv/eONbp9GmL/vvf9urRI1iJidL8+WZXBgAAAH9GcDJDwdDkbASRkmLcfuUVqXp1aetWIyWkpEgXXyydPi1lZEgjRkj16kmdOklPPy39/rupb8WT5s+Xbr5Zcjjc1+/ZI910E+EJAAAAlYfgZAabrejuec7wZLMZ0ypt2hi3N26UfvlFeuIJ6dJLjeSwerX0f/8nXXSRlJRknPtpw4bCqcJP2GzSvfcW/fac68aMEbvtAQAAoFLQjtwM5zvB7blakTduLP3738ayZ4/04YfGFMvy5dIPPxjLpElSo0ZSv37GsVF/+9uZ46h83IoV0u7d577f4ZB27ZKWLjX2aAQAAAAqkn/8qg409eoZu+wtWSIdPCjNmiVdf71UpYqxi98zz0idOxvb3XOPtHixcdZYH1bSw7r69DHe+v/9n3F42IEDlVsXAAAAAgMzTr6uZk1p6FBjOXlS+vxzIzF8/LG0f79xct2XXpKqVZP69jVmo3r1Mjr4+ZCSnuzWZpNWrTIWp0aNjEPCOnc2Llu2NE6dBQAAAJQUwcmfVK0q3XijseTlScuWGbvzffihMfXy1lvGEh5uhKf+/aVrr5Vq1DC78mJdfrlUv76xl2JRxzlZLMb9GRnSt9+eCU8//mhMwm3darx1SYqKMvZi7NTJWC691MiVAAAAwLkQnPxVaKgRjnr1kqZPN5pJLFhgLNu2SR98YCzBwVLXrkaIuuGGkk/teJjVKv33v0b3PIvFPTxZ/joX7rRpUtOmxjJkiLHu2DH3IPXNN9Lx40bAysg48/iLLz4TpDp3NmapLJxjFwAAAH8hOAUCq1W67DJjefppo/veggXGbNSPPxrHSi1ZYhw31bGjsTtfv35Gxz4v0r+/NG+e0V2vYKOI+vWN0NS/f+HHVKtmNItwNoyw2Yy37AxSq1YZs1EbNxrLSy8Z29WteyZIdepknHi3SpVKf4sAAADwUgSnQONsc96mjdGF79dfz8xEffONMTO1erXRva9VqzMd+lq39oopmP79jT4Yy5ad1mefZap37zbq1i24xMcsWa1G9/akJOmf/zTW7d9vvGVnkFq3zui54ZyUk6SQECM8FQxTXjo5BwAAgEpAcAp0RbU5X7DAOD7KOQ0zebLUsKGRWvr1M2alTGxzbrVKXbo4dPLkHnXpklTuRg+xsWcm2SQpN1dav/5MkFq50jhE7JtvjGXqVGO7xMQzDSc6dTJ29wvmXxQAAIBf4mceznC2OR8xQjpyRPrkE2N3vkWLjOOinnnGWGJjjWmf/v2N46NCQ82uvEKFhRnZsGNH6f77jeOptm1z371v40Zp+3ZjmT3beFxkpNFowhmk/vY3qXp1E98IAAAAKgzBCUWrWdPosDBkiNHmfNEiI0R98knhNufXXmuEKB9sc14SFovRLKJRI+m224x1WVnSmjVngtTq1ca6pUuNxfm4Fi3cW6FfdJFX7PEIAACAUiI4oXhVqxrBqH//M23OFywwDgA6cMCYcpk9+0yb8379jDBVs6bZlVea6Gipe3djkYymE5s3n9m1b9Uq6bffpJ9+MpaZM43tatd2P04qOdn42AAAAODdCE4onYJtzl94wTjox9mhr2Cbc6tV6tbNCFE33CDFx5tceOWyWo1jnC6+WLr7bmPdwYPuTSfWrpUOH5Y++shYJOOYqHbt3Fuh+/lHBQAA4JMITig7q9X4pd+5s/TUU9IPPxgBasEC4yAgZ5vzkSONA36czSW8rM15Zalb1zgU7Prrjdt5edL337s3ndi3z9jlb80ao6W6JDVo4D4r1bo1TScAAADMxs8xVAyL5Uyf70mTjP3UnDNRznZ033zj3ua8Xz9j+wA56Cc01Ggeceml0n33GU0nduxwbzqxYYOxbscO6e23jcdFRBRuOuHHe0ECAAB4JYITKsdFF0n/93/Gsnev0eZ8/nxp+fLCbc6d54oyuc25p1ksRkvzxETp1luNdSdOFG46cfSocVjZsmVnHtu8uXvTiSZNis+fNpu0YoUxyxUXJ11+ucrdyh0AACBQEJxQ+eLjjbPN/vOfZ9qcL1ggff65cVzU1KnGEhNjHA/Vr59xfJSftTkvichI6corjUWS7Hbp55/dd+/75RejEcXmzdIrrxjb1azpvnvfJZcYM1VO8+dL994r7d59Zl39+tJ//2tkVgAAAJwfwQmedb425wcOFG5z3q+fdPXVRme/tDRjiiQlpfDzpqcbUyppaZ5+R5UqKMhoad6ihXTnnca6w4fdm06sWXMmj37yibFNcLDUpo0RooKDpf/8x9g1sKA9e6SbbpLmzSM8AQAAFIfgBPOc3eZ8+XIjRJ3d5rxKFaOLn9Vq3C9J48adeZ70dCk11dj1LwDUri317WsskvHRbdjgPiu1Z4+0bp2xnIszSP3zn8aelbVqGSfsjYgImMPOAAAASozgBO8QGir17GksBducL1ggbd1qHCMlGb/oU1Nl/eYb1bjiCgUtXixNn24Ep6JmogJAaKixa94llxi740nSrl1GgHr3XeMjPJ+DB40eHU7BwUaAqlbNuDx7Odd6531RUf4VvGw26csvLfrqq3qqWtWibt04NgwAgEBEcIL3KarNubND38aNkqSghQt1xcKFZx4zebL05JPGr/caNc4s57td8HpkpF/92k9IkAYONGaVigtOkvH2T50yQsLp08bugIcPl+21g4KKDlclDWLR0d7TI+TMsWHBkpI1dSrHhgEAEKgITvBuBducp6W52pw7HnxQFodDDkkWi8VICDk50v79xlJaVmvJQ9bZt6tV89opiLi4km338cdSly5SdrbRxe/s5dixotcXvO/PP6X8fKOhxZ9/GktZWCxGeCrrrFd0dMWc92r+fOMYMI4NAwAAEsEJvuaii6ScHFkcDtmCg2U9fdoIVPfee+bXuvNXfFG3z77P+WvfZpP++MNYyiI6umQhq6hAFhZWMZ9NES6/XHomKk1Hj1uVrsK7MqYoXTWibbr88jRZLMZhZ1WrSvXqlf61nNm1NGHr7CUnx3ieY8eMpawiI0u/i2HB61arMaTODk3O92mxSGPGGCc39tLM7BVogQ8A8CcEJ/iWvxpB2CZO1Cdt2+ra77+XdeJE45dsSopxUqTScDiMfdRKErKKun3ypPE8WVnGsmNH6d9TeHjpdy103q5a9by7GFqt0tXXWNXinVRJcgtPKUrXZKVqU5/JFfJj1mIx3kp4eMlnus6Wm3vuUFWSIOb8Ok6cMJaC7ddLIyzMqOVcHA7jOLKhQ41zaIWFlWwJDT3/fd6yi2JFoAV+2XFcXdkQ1AFUNoITfEeB7nn2ceOkhQtlf/hhWa1WY71U+gYRFovRRi4iomzTLHl5Z369Fxeyzr597NiZ4HbqlHGi4NIKDi42ZLW4Kk67dg3Q5JWpitVe/UdjdY9e1P36j7b0G6cWL91rvH5oqOm/MsLCpLp1jaUs8vPdA1ZpZ72OHzeeJzdXmqg02WTVI0XM1E1QuqyyadLstLIVeg4hIaUPXGUJaaV5XFkO/ds8IE2Z71q1+6zPbs8eKfPGdDW/xabmc9Mq5kPzJ2lp2rTFql5fpxQ6rm7RZelq0dT/TrlQUQjqZUdQLzvCetn48pgjOMF32GxGE4iUFOMXspMzLNlsnq8pNLTsv/RtNmOWqjShq+D106eN5dAhYzmPhL8uR2iGRmiGa33TBY9LCx4/s2FQkPGeQkKMy4LL2evKe7siniM42O2XfUiI0a69du3Sfx2S8XFmZRmnF9t0q1XpMgJ5wfA0QelKV6pSNFn9+kl16hhBq+CSl1d4XVFLwWEsGbfz843ZMm9xrjB3rrAVEiK1XGDVZKXKIffP7mGHMcv56IeTFfzEma/QanW/9MQ6q9X7Zvg2bTFmh4fJ/XMbvjtdLd5J1aaBk9XCtOq8F0G97GiAU3aE9TLwgz8OEZzgO873j8kXW5FbrWdmiBo2LN1jHQ5jv7TSHM919Kj000/ur3922LTbjQONcnLK9948qQIDXXBoqGqGhmqANURPR4dqUVZPpStVHbRGH+k69dFC9dMHel/9lVWzoeb1n6Og4CDjF3gZFruClG87s+SdLrzk5he+PPt6Tl6QcvKtZ66fZ8nNs3ggzKUoX3ILngUD5yO5KdK48z+DJ1gslRPOyvIYi0X678IUjVbhz23yX5/bC4tSNOUlY/ugIOMx5xpe57vPrMcWd19ZZjdtNunTz88f1J/+fLKa2HznL9qeQuAsOz67svGHPw5ZHI6iDn/2X1lZWapWrZqOHTum6Ohos8tBGeXn52vhwoXq06ePQkJCzC7HNzh3dQwNNaZEJk+WHn7Y+FWcl3dmKe52SbYp7+3zbYPyO8+vYofz0hIkWYzbDstfi4Jk/+u6XWcuCy4ns4N0+E/jeqz2KUF7ZJdFQXJop+prr4xdYqOipLBQh+T4qwmHwyGHcdN12+0+1/qzbxv/C3N7zF9XnZ03Jcki9//VFbx9rutlva+8z1FDf6qm/jS6hko6pNo6oBjZZJVdQbLJ6lr86bYxpqxyBFllt1j/Go9nbhtj0epap6Ag5Z626vBRq+7XM5qgRzVJKXpUEzReUzRJaUrRJD2iVCUmnjnVQXkX52ylLy8Oh/TjwHSNz/7rjxlFzKo/XnWyOn6a4gr2Zy9S0esr4n5vfW7J+Pvif2qm64Gsc392T0dP1n1HUgjrBdhsxmHow3YX+CNagT+qpWqyZiWkaNs2z/+RozTZgOAEn0RwKqUCx4cpJaXwbV/hcBj703kovO34LV/ff5unvqfmyiq7bArS8ipXq2Vzu2Lr2I3/g5q52GzGZWD9ZxwoNZsKh3y7guSQpcj1JbnfGx9b2uftouXqoaVapB5aoh66Skt0tRbrM/XSEvWQJDlkOe+lp+/zlue+SfM0UHP1tgbofd2km/SeBupdzdXNWqD+CgtxyBrkUJDFIYuM6xYZt4MsDlksDgUVvF3C6wUf57r91zrntpazbxd4XKHLc21XxDbnfEyB+133nbU+J9uh3buN20nKVDtlyqYgWWV3C6DLlkldu8qjCE7nQXDyDwSnUjhXSPLV8ORh9knpCkpL1WlriIJt+bKnTVbQRC/7vBx/Tc2YHeTsdtny7Ro2xK4jh+0apDm6TbOVr2CF6LRm61a9qwGqVduimTP/+qvi2ftnFbxd1vsq6nk8+Brr10uj/mX8IBuu13S3ZipPIQpVvl7RcM3RYAXJrmeesKl1S9uZ0GyznVkK3j7ffR56rMNmk2z2vy5t0mmbHAW3PW1s77DZZHE+xm53XZfjzLaWArctNptkt8litwuAb8tVqKroTBvbOXOkQYM8W0NpsgHHOAH+rmBTjYLMbKrhK9KN0GSbOFGfOtvfp6VKQfKusOncjyQoyOxKZJXU7yVjP//bNLvQ7hhb1ExtXkqR9QazK/UuSZdKu54w9vW/WzMLfW471FCzElLU8n4ZH7IPsJx1WRls+XZd1NCm/XtsGq/HlKp05SpUYcrTYxqnaRqr+vF2rf3WLmtQMX9cKO6PD5V9vwdr2Lvbrk8+PjP3NFSvu2bV5+hW1+fbs7tDMTE6M6t99mVR6yrzvmK2cUgF9veVXHMD9r9uF9zeXvQ2busK7D/svDfrmEObNp3ZtbazVipIDtll0Qpd7ppnadHCoqhqzn38LHJYjPWu23+tU1GXpbhuzIQVcV+B+922Kcl951ssFjkcJdvW7jjzmD/+sGjtd8btK/WFeipDp2VVmPI0QemuGaeyns7EYxwB5tixYw5JjmPHjpldCsohLy/P8cEHHzjy8vLMLgX+avJkYx5n8mT38VZgPc7hr8/oqejJjjPTYQ7HU9F8dufz00Dj80mR++eWImP9TwP53Iry/vtnPqMJf312E3Tms3z/fbMr9D6nTzsc9es7HBbLmc8qR6Guz9BicTgSEozt4I7Prmycn9v5/q2a9bmVJhsw4wQARfHG9ve+4q/P7r6HUpTsdo6TFOkx8dmdQ4umNm0aOFmvfZ0iFWhxPCshRQM7G/ejsP4/pav/XwfkP5Jl/Pt8RCmqFi1NzkqVfpLU34tmiL2A1Wq0zc688UzXxoIznBaH1GYazQ2KwmdXNlbrXy3H3zEaQThnmB5RiiySJitVAztLVqt3/1slOAFAUdLSzn2fN+2m543++uysKuIgXz67c0tLUwtJ223SsmWn9dlnmerdu426dQv2+h8TpiKolwmBs+z47MrGH/44RHACAMCLWK1Sly4OnTy5R126JPGX6+IQ1MumQOBs4xbUCZzFIqyXjR/8cYjgBAAAEGgKBM5CQZ3AeX6E9XLx5T8Omd+CCQAAAAC8HMEJAAAAAIpBcAIAAACAYhCcAAAAAKAYBCcAAAAAKAbBCQAAAACKQXACAAAAgGIQnAAAAACgGAQnAAAAACgGwQkAAAAAikFwAgAAAIBiEJwAAAAAoBgEJwAAAAAoBsEJAAAAAIoRbHYBnuZwOCRJWVlZJleC8sjPz1d2draysrIUEhJidjnwc4w3eBpjDp7EeIOnedOYc2YCZ0Y4n4ALTsePH5ckJSQkmFwJAAAAAG9w/PhxVatW7bzbWBwliVd+xG63a+/evYqKipLFYjG7HJRRVlaWEhIStGvXLkVHR5tdDvwc4w2expiDJzHe4GneNOYcDoeOHz+u+Ph4BQWd/yimgJtxCgoKUv369c0uAxUkOjra9H9wCByMN3gaYw6exHiDp3nLmCtupsmJ5hAAAAAAUAyCEwAAAAAUg+AEnxQWFqaJEycqLCzM7FIQABhv8DTGHDyJ8QZP89UxF3DNIQAAAACgtJhxAgAAAIBiEJwAAAAAoBgEJwAAAAAoBsEJAAAAAIpBcILPmDJlii655BJFRUWpbt26uuGGG7Rlyxazy0IAefzxx2WxWDRmzBizS4Gf2rNnj2677TbVqlVL4eHhatWqldatW2d2WfBTNptNKSkpatiwocLDw3XhhRcqPT1d9A1DRfnqq6/Ut29fxcfHy2Kx6IMPPnC73+FwKDU1VXFxcQoPD1f37t3166+/mlNsCRCc4DO+/PJLjRw5Ut98840yMjKUn5+vnj176uTJk2aXhgCwdu1avfTSS2rdurXZpcBP/fnnn+rcubNCQkL02WefadOmTXrmmWdUo0YNs0uDn3riiSf04osv6vnnn9fmzZv1xBNP6Mknn9Rzzz1ndmnwEydPnlRSUpJeeOGFIu9/8skn9eyzz2rGjBn69ttvVbVqVfXq1Us5OTkerrRkaEcOn3Xo0CHVrVtXX375pa644gqzy4EfO3HihNq1a6fp06frkUceUZs2bTRt2jSzy4KfGTdunFauXKkVK1aYXQoCxLXXXquYmBi98sorrnU33nijwsPD9dZbb5lYGfyRxWLRggULdMMNN0gyZpvi4+N1//3364EHHpAkHTt2TDExMZo1a5YGDhxoYrVFY8YJPuvYsWOSpJo1a5pcCfzdyJEjdc0116h79+5mlwI/9tFHHyk5OVk333yz6tatq7Zt22rmzJlmlwU/1qlTJy1dulS//PKLJGnDhg36+uuv1bt3b5MrQyDYtm2b9u/f7/b/1mrVqunSSy/V6tWrTazs3ILNLgAoC7vdrjFjxqhz5866+OKLzS4Hfuydd97R+vXrtXbtWrNLgZ/bunWrXnzxRY0dO1YPPfSQ1q5dq9GjRys0NFRDhw41uzz4oXHjxikrK0vNmjWT1WqVzWbTo48+qsGDB5tdGgLA/v37JUkxMTFu62NiYlz3eRuCE3zSyJEj9eOPP+rrr782uxT4sV27dunee+9VRkaGqlSpYnY58HN2u13Jycl67LHHJElt27bVjz/+qBkzZhCcUCneffddzZ49W3PmzFHLli2VmZmpMWPGKD4+njEHFIFd9eBzRo0apU8++UTLli1T/fr1zS4Hfuy7777TwYMH1a5dOwUHBys4OFhffvmlnn32WQUHB8tms5ldIvxIXFycWrRo4bauefPm2rlzp0kVwd/93//9n8aNG6eBAweqVatWuv3223XfffdpypQpZpeGABAbGytJOnDggNv6AwcOuO7zNgQn+AyHw6FRo0ZpwYIF+uKLL9SwYUOzS4Kfu+qqq7Rx40ZlZma6luTkZA0ePFiZmZmyWq1mlwg/0rlz50KnWPjll1/UoEEDkyqCv8vOzlZQkPtPQavVKrvdblJFCCQNGzZUbGysli5d6lqXlZWlb7/9Vh07djSxsnNjVz34jJEjR2rOnDn68MMPFRUV5dr/tVq1agoPDze5OvijqKioQsfQVa1aVbVq1eLYOlS4++67T506ddJjjz2mW265RWvWrNHLL7+sl19+2ezS4Kf69u2rRx99VBdccIFatmyp77//XlOnTtXf//53s0uDnzhx4oR+++031+1t27YpMzNTNWvW1AUXXKAxY8bokUceUePGjdWwYUOlpKQoPj7e1XnP29COHD7DYrEUuf61117TsGHDPFsMAlbXrl1pR45K88knn2j8+PH69ddf1bBhQ40dO1Z33XWX2WXBTx0/flwpKSlasGCBDh48qPj4eA0aNEipqakKDQ01uzz4geXLl6tbt26F1g8dOlSzZs2Sw+HQxIkT9fLLL+vo0aO67LLLNH36dDVp0sSEaotHcAIAAACAYnCMEwAAAAAUg+AEAAAAAMUgOAEAAABAMQhOAAAAAFAMghMAAAAAFIPgBAAAAADFIDgBAAAAQDEITgAAAABQDIITAAClYLFY9MEHH5hdBgDAwwhOAACfMWzYMFkslkLL1VdfbXZpAAA/F2x2AQAAlMbVV1+t1157zW1dWFiYSdUAAAIFM04AAJ8SFham2NhYt6VGjRqSjN3oXnzxRfXu3Vvh4eFq1KiR5s2b5/b4jRs36sorr1R4eLhq1aqlu+++WydOnHDb5tVXX1XLli0VFhamuLg4jRo1yu3+w4cPq1+/foqIiFDjxo310UcfVe6bBgCYjuAEAPArKSkpuvHGG7VhwwYNHjxYAwcO1ObNmyVJJ0+eVK9evVSjRg2tXbtW7733npYsWeIWjF588UWNHDlSd999tzZu3KiPPvpIF110kdtrTJo0Sbfccot++OEH9enTR4MHD9aRI0c8+j4BAJ5lcTgcDrOLAACgJIYNG6a33npLVapUcVv/0EMP6aGHHpLFYtE999yjF1980XXf3/72N7Vr107Tp0/XzJkz9eCDD2rXrl2qWrWqJGnhwoXq27ev9u7dq5iYGNWrV0/Dhw/XI488UmQNFotFEyZMUHp6uiQjjEVGRuqzzz7jWCsA8GMc4wQA8CndunVzC0aSVLNmTdf1jh07ut3XsWNHZWZmSpI2b96spKQkV2iSpM6dO8tut2vLli2yWCzau3evrrrqqvPW0Lp1a9f1qlWrKjo6WgcPHizrWwIA+ACCEwDAp1StWrXQrnMVJTw8vETbhYSEuN22WCyy2+2VURIAwEtwjBMAwK988803hW43b95cktS8eXNt2LBBJ0+edN2/cuVKBQUFqWnTpoqKilJiYqKWLl3q0ZoBAN6PGScAgE/Jzc3V/v373dYFBwerdu3akqT33ntPycnJuuyyyzR79mytWbNGr7zyiiRp8ODBmjhxooYOHaq0tDQdOnRI//rXv3T77bcrJiZGkpSWlqZ77rlHdevWVe/evXX8+HGtXLlS//rXvzz7RgEAXoXgBADwKZ9//rni4uLc1jVt2lQ///yzJKPj3TvvvKMRI0YoLi5Ob7/9tlq0aCFJioiI0KJFi3TvvffqkksuUUREhG688UZNnTrV9VxDhw5VTk6O/vOf/+iBBx5Q7dq1ddNNN3nuDQIAvBJd9QAAfsNisWjBggW64YYbzC4FAOBnOMYJAAAAAIpBcAIAAACAYnCMEwDAb7D3OQCgsjDjBAAAAADFIDgBAAAAQDEITgAAAABQDIITAAAAABSD4AQAAAAAxSA4AQAAAEAxCE4AAAAAUAyCEwAAAAAU4/8BeJYaGrUudbgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "num_epochs = 10\n",
    "\n",
    "if not skip_training:\n",
    "    epoch_train_losses = []\n",
    "    epoch_validation_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model = model.to(device)\n",
    "        model.train()  # Set model to training mode\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        for src_batch, tgt_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # set input source as src_batch\n",
    "            # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
    "            # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
    "            # use input source and input target (tgt_input) as input to the model\n",
    "            # expexted target will be used in loss to compare it with the model output.\n",
    "            # Remember to use padding and target causal masks on the model call:\n",
    "            # get padding mask of source,\n",
    "            # get padding mask of input target, convert it to float (.float()),\n",
    "            # get tgt_mask of input target,\n",
    "            # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
    "            src_batch = src_batch.to(device)\n",
    "            tgt_batch = tgt_batch.to(device)\n",
    "\n",
    "            tgt_input = tgt_batch[:, :-1]\n",
    "            tgt_expected = tgt_batch[:, 1:]\n",
    "\n",
    "            src_padding_mask = model.create_pad_mask(src_batch)\n",
    "            tgt_padding_mask = model.create_pad_mask(tgt_input).float()\n",
    "            \n",
    "            tgt_mask = model.get_tgt_mask(tgt_input)\n",
    "            output_decoder, output = model(src_batch, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask)\n",
    "\n",
    "            output = output.to(device)\n",
    "            output = output.contiguous().view(-1, vsize_tgt)\n",
    "            tgt_expected = tgt_expected.contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_expected)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_samples += src_batch.shape[0]\n",
    "\n",
    "        epoch_train_loss = total_loss / len(train_loader)\n",
    "        epoch_train_loss = round(epoch_train_loss, 4)\n",
    "        epoch_train_losses.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss}\")\n",
    "\n",
    "        ################################################################\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        num_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for src_batch, tgt_batch in val_loader:\n",
    "                # set input source as src_batch\n",
    "                # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
    "                # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
    "                # use input source and input target (tgt_input) as input to the model\n",
    "                # expexted target will be used in loss to compare it with the model output.\n",
    "                # Remember to use padding and target causal masks on the model call:\n",
    "                # get padding mask of source,\n",
    "                # get padding mask of input target, convert it to float (.float()),\n",
    "                # get tgt_mask of input target,\n",
    "                # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
    "                src_batch = src_batch.to(device)\n",
    "                tgt_batch = tgt_batch.to(device)\n",
    "\n",
    "                tgt_input = tgt_batch[:, :-1]\n",
    "                tgt_expected = tgt_batch[:, 1:]\n",
    "\n",
    "                src_padding_mask = model.create_pad_mask(src_batch)\n",
    "                tgt_padding_mask = model.create_pad_mask(tgt_input).float()\n",
    "\n",
    "                tgt_mask = model.get_tgt_mask(tgt_input)\n",
    "                output_decoder, output = model(src_batch, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask)\n",
    "\n",
    "                output = output.to(device)\n",
    "                output = output.contiguous().view(-1, vsize_tgt)\n",
    "\n",
    "                tgt_expected = tgt_expected.contiguous().view(-1)\n",
    "                loss = criterion(output, tgt_expected)\n",
    "                validation_loss += loss.item()\n",
    "                num_samples += src_batch.shape[0]\n",
    "\n",
    "            epoch_validation_loss = validation_loss / len(val_loader)\n",
    "            epoch_validation_loss = round(epoch_validation_loss, 4)\n",
    "            epoch_validation_losses.append(epoch_validation_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {epoch_validation_loss}\")\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, epoch_train_losses, label='Train Loss', color='blue', marker='o')\n",
    "    plt.plot(epochs, epoch_validation_losses, label='Validation Loss', color='red', marker='x')\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cd6f4b79c9eb03096892f79e8f40433",
     "grade": false,
     "grade_id": "cell-c54877793b096ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 4: Autoregressive Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": true,
    "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d107bba2e8b29eabdd5bde898afb0b",
     "grade": false,
     "grade_id": "cell-4dae7ac8dd1330c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3e6d6a97-bb24-4ed4-9f81-2bde661e2a0a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_sentence: new jersey est parfois calme pendant l' automne.\n",
      "translated_sentence: quiet during autumn <EOS>\n",
      "----------\n",
      "original_sentence: california est généralement calme en mars.\n",
      "translated_sentence: quiet during march <EOS>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "seq_len=10\n",
    "start_token=1\n",
    "end_token=2\n",
    "model.eval()\n",
    "\n",
    "# Convert src_sentence to tokenized integers in the vocabulary dictionary\n",
    "example_source_sentences = [\"new jersey est parfois calme pendant l' automne.\", \"california est généralement calme en mars.\"]\n",
    "example_tokenized = tokenize(example_source_sentences)\n",
    "src_sentences = []\n",
    "for ex in example_tokenized:\n",
    "    ex_inds = []\n",
    "    for t in ex:\n",
    "        t_ind = fr_word2idx [t]\n",
    "        ex_inds.append(t_ind)\n",
    "    src_sentences.append(ex_inds)\n",
    "\n",
    "translated_sequences = []\n",
    "for counter, src_sentence in enumerate(src_sentences):\n",
    "    # Convert source tokens to Tensor\n",
    "    src_tensor = torch.tensor(src_sentence, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, src_seq_length)\n",
    "\n",
    "    # 1. create src_padding_mask\n",
    "    # 2. get \"memory\" by passing source with create src_padding_mask through encode block (model.encode)\n",
    "    src_padding_mask = model.create_pad_mask(src_tensor)\n",
    "    memory = model.encode(src_tensor, src_padding_mask)\n",
    "\n",
    "    # initialize the predicted tgt_tokens (translation) with start token\n",
    "    tgt_tokens = torch.ones(1, 1).fill_(start_token).type(torch.long).to(device) #(1,1)\n",
    "\n",
    "    for i in range(seq_len-1):\n",
    "        # 1. Mask out the unpredicted tokens in the target (i.e., get tgt_mask)\n",
    "        # 2. get output by passing target (the generated part up to current `i`) and memory to decode block (model.decode)\n",
    "        # 3. remember to pass also tgt_mask\n",
    "        # 4. get a probability vector by passing output through linear layer (projection to vocabulary size)\n",
    "        # 5. use \"torch.max\" to get the index of the predicted word\n",
    "        # 6. Convert it to a tensor on device (name it as \"next_tgt_item\")\n",
    "        # 7. add \"next_tgt_item\" to tgt_tokens (use torch.cat)\n",
    "        # 8. Stop (break) if \"end_token\" is generated\n",
    "        tgt_mask = model.get_tgt_mask(tgt_tokens)\n",
    "        output_decoder = model.decode(tgt_tokens, memory, tgt_mask, None)\n",
    "        output = model.linear(output_decoder)\n",
    "        output = output.transpose(0, 1)\n",
    "        prob = torch.max(output, dim=2)[1]\n",
    "        next_tgt_item = prob[:, -1].unsqueeze(1)\n",
    "        tgt_tokens = torch.cat((tgt_tokens, next_tgt_item), dim=1)\n",
    "        if next_tgt_item.item() == end_token:\n",
    "            break\n",
    "\n",
    "    translated_tokens = tgt_tokens.squeeze().tolist()\n",
    "    translated_sentence = ' '.join ([en_idx2word[i] for i in translated_tokens[1:]])\n",
    "    translated_sequences.append(translated_tokens)\n",
    "    print(\"original_sentence:\", example_source_sentences[counter])\n",
    "    print(\"translated_sentence:\", translated_sentence)\n",
    "    print(10*'-')\n",
    "\n",
    "np.save('translation.npy', np.array(translated_sequences, dtype=object))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dataml200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
